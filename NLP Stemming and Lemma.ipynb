{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1RSvVnqxDQI0TzqCXIQKvkvuAelbw8NX0","timestamp":1742925994655}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["pip install nltk"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-V5nR5UKQb6-","executionInfo":{"status":"ok","timestamp":1741764549101,"user_tz":-330,"elapsed":3018,"user":{"displayName":"MOHAMMAD BILAL SHAIKH","userId":"01000845945659947790"}},"outputId":"d1dc5293-65da-4522-d59f-00d2a1c17045"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"]}]},{"cell_type":"markdown","source":["Lemmatization"],"metadata":{"id":"yU6keb4aSBt2"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cD93lD5VO-93","executionInfo":{"status":"ok","timestamp":1741764794058,"user_tz":-330,"elapsed":2046,"user":{"displayName":"MOHAMMAD BILAL SHAIKH","userId":"01000845945659947790"}},"outputId":"d82401c5-3d42-4e3a-eb81-3cf2faa2045f"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"]},{"output_type":"stream","name":"stdout","text":["Lemmatized word: run\n"]}],"source":["import nltk\n","from nltk.stem import WordNetLemmatizer\n","from nltk.corpus import wordnet\n","\n","# Download necessary NLTK data\n","nltk.download('wordnet')\n","nltk.download('omw-1.4') #This is needed in some environments to address compatibilities\n","nltk.download('averaged_perceptron_tagger')\n","#To resolve the LookupError, download the 'averaged_perceptron_tagger_eng' resource\n","nltk.download('averaged_perceptron_tagger_eng')\n","\n","# Function to get POS tag\n","def get_wordnet_pos(word):\n","    tag = nltk.pos_tag([word])[0][1][0].upper()\n","    tag_dict = {\"J\": wordnet.ADJ, \"N\": wordnet.NOUN, \"V\": wordnet.VERB, \"R\": wordnet.ADV}\n","    return tag_dict.get(tag, wordnet.NOUN)\n","\n","lemmatizer = WordNetLemmatizer()\n","word = \"running\"\n","lemma = lemmatizer.lemmatize(word, get_wordnet_pos(word))\n","print(f\"Lemmatized word: {lemma}\")\n"]},{"cell_type":"markdown","source":["Stemming"],"metadata":{"id":"8veT17UrSFsO"}},{"cell_type":"code","source":["import nltk\n","from nltk.stem import PorterStemmer\n","\n","stemmer = PorterStemmer()\n","word = \"running\"\n","stem = stemmer.stem(word)\n","print(f\"Stemmed word: {stem}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9g4ghaa8PwX_","executionInfo":{"status":"ok","timestamp":1741764886295,"user_tz":-330,"elapsed":8,"user":{"displayName":"MOHAMMAD BILAL SHAIKH","userId":"01000845945659947790"}},"outputId":"12b9d868-0010-43ba-f950-426925c371e0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Stemmed word: run\n"]}]},{"cell_type":"markdown","source":["Stemming vs Lemmatization"],"metadata":{"id":"S0ukaeBrSHy-"}},{"cell_type":"code","source":["import nltk\n","from nltk.stem import PorterStemmer, WordNetLemmatizer\n","from nltk.corpus import wordnet\n","\n","# Download necessary NLTK data\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","nltk.download('averaged_perceptron_tagger')\n","# Download the 'punkt_tab' data package\n","nltk.download('punkt_tab') # This line is added to download the required data package.\n","\n","\n","# Sample text\n","text = \"The striped bats are hanging on their feet for best\"\n","\n","# Tokenize the text\n","words = nltk.word_tokenize(text)\n","\n","# Initialize the stemmer and lemmatizer\n","stemmer = PorterStemmer()\n","lemmatizer = WordNetLemmatizer()\n","\n","# Apply stemming\n","stemmed_words = [stemmer.stem(word) for word in words]\n","\n","# Function to get the part of speech tag for lemmatization\n","def get_wordnet_pos(word):\n","    tag = nltk.pos_tag([word])[0][1][0].upper()\n","    tag_dict = {\"J\": wordnet.ADJ, \"N\": wordnet.NOUN, \"V\": wordnet.VERB, \"R\": wordnet.ADV}\n","    return tag_dict.get(tag, wordnet.NOUN)\n","\n","# Apply lemmatization\n","lemmatized_words = [lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in words]\n","\n","# Print results\n","print(\"Original Text: \", text)\n","print(\"Tokenized Words: \", words)\n","print(\"Stemmed Words: \", stemmed_words)\n","print(\"Lemmatized Words: \", lemmatized_words)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xCnKS4iJQJw3","executionInfo":{"status":"ok","timestamp":1741764939735,"user_tz":-330,"elapsed":771,"user":{"displayName":"MOHAMMAD BILAL SHAIKH","userId":"01000845945659947790"}},"outputId":"7e2bcac6-6bd1-4d3f-da16-7c5ad6030945"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"]},{"output_type":"stream","name":"stdout","text":["Original Text:  The striped bats are hanging on their feet for best\n","Tokenized Words:  ['The', 'striped', 'bats', 'are', 'hanging', 'on', 'their', 'feet', 'for', 'best']\n","Stemmed Words:  ['the', 'stripe', 'bat', 'are', 'hang', 'on', 'their', 'feet', 'for', 'best']\n","Lemmatized Words:  ['The', 'strip', 'bat', 'be', 'hang', 'on', 'their', 'foot', 'for', 'best']\n"]}]}]}